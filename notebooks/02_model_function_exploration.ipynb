{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperModel, WhisperConfig, WhisperFeatureExtractor, WhisperForConditionalGeneration\n",
    "from transformers import WhisperProcessor, WhisperTokenizer\n",
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"openai/whisper-medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_whisper = WhisperModel.from_pretrained(MODEL_NAME)\n",
    "pretrained_whisper_tokenizer = WhisperTokenizer.from_pretrained(MODEL_NAME)\n",
    "whisper_for_gen = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "whisper_processor = WhisperProcessor.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhisperConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50256\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"d_model\": 256,\n",
      "  \"decoder_attention_heads\": 4,\n",
      "  \"decoder_ffn_dim\": 1536,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 50257,\n",
      "  \"dropout\": 0.0,\n",
      "  \"encoder_attention_heads\": 4,\n",
      "  \"encoder_ffn_dim\": 1536,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"max_source_positions\": 1500,\n",
      "  \"max_target_positions\": 448,\n",
      "  \"model_type\": \"whisper\",\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51865\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a look at whisper config\n",
    "config = WhisperConfig()\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOS token <|endoftext|> ===> 50257\n",
      "EOS token <|endoftext|> ===> 50257\n"
     ]
    }
   ],
   "source": [
    "# look at the special tokens in the whisper_tokenizer\n",
    "# print(pretrained_whisper_tokenizer.all_special_tokens)\n",
    "print(\"BOS token\", pretrained_whisper_tokenizer.bos_token, \"===>\", pretrained_whisper_tokenizer.bos_token_id)\n",
    "print(\"EOS token\", pretrained_whisper_tokenizer.eos_token, \"===>\", pretrained_whisper_tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs the model is forced to predict at each timestep\n",
      "timestep 1: <|en|> => 50259\n",
      "IDs the model is forced to predict at each timestep\n",
      "timestep 2: <|transcribe|> => 50359\n",
      "IDs the model is forced to predict at each timestep\n",
      "timestep 3: <|notimestamps|> => 50363\n",
      "(\", 1) (#, 2) (', 6) ((, 7) (), 8) (*, 9) (+, 10) (-, 12) (/, 14) (:, 25) (;, 26) (<, 27) (=, 28) (>, 29) (@, 31) ([, 58) (\\, 59) (], 60) (^, 61) (_, 62) (`, 63) ({, 90) (|, 91) (}, 92) (~, 93) ( -, 359) ( \", 503) ( (, 522) ( [, 542) ( �, 873) (>>, 893) ( >>, 902) (--, 918) ( ', 922) ( ♪, 931) ( --, 1350) ( *, 1853) ( :, 1982) ( /, 2460) ( <, 2627) (「, 3246) (」, 3253) (�, 3268) ( #, 3536) ( ♫, 3846) (♪, 3961) ( ], 4183) ( +, 4667) ( =, 6585) ( -(, 6647) ( ), 7273) ( ♪♪, 9061) ()), 9383) ( @, 10428) ( {, 10929) ( ~, 11938) ( \\, 12033) ( >, 12331) ( ;, 12562) ( >>>, 13793) (♫, 14157) ( -[, 14635) ( ((, 15265) ( (\", 15618) (『, 16553) (』, 16604) ( |, 18362) ( ^, 18956) (---, 20075) ( 「, 21675) ( ♬, 22520) (♪♪, 26130) ( _, 26161) ( ))), 26435) ( `, 28279) (}}, 29464) ( ♪♪♪, 31650) ( )), 32302) ( ---, 32470) ( ♩, 36865) (♬, 42863) ( <<, 47425) ( }, 49870) ( (', 50254) (<|startoftranscript|>, 50258) (<|startoflm|>, 50360) (<|startofprev|>, 50361) (<|nocaptions|>, 50362) "
     ]
    }
   ],
   "source": [
    "forced_ids = whisper_for_gen.config.forced_decoder_ids\n",
    "for idx, token_id in forced_ids:\n",
    "    token = pretrained_whisper_tokenizer.decode(token_id)\n",
    "    print(\"IDs the model is forced to predict at each timestep\")\n",
    "    print(f\"timestep {idx}: {token} => {token_id}\")\n",
    "\n",
    "ids_to_suppress = whisper_for_gen.config.suppress_tokens\n",
    "for sup_id in ids_to_suppress:\n",
    "    sup_token = pretrained_whisper_tokenizer.decode(sup_id)\n",
    "    print(f\"({sup_token}, {sup_id})\", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_whisper.config.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silence decoded : ['<|startoftranscript|><|nocaptions|><|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "silences = torch.zeros(size=(16000,))\n",
    "\n",
    "# predict all the tokens # donot suppress any token\n",
    "whisper_for_gen.config.suppress_tokens = []\n",
    "# donot force the decoder to predict the language token and task token initally\n",
    "whisper_for_gen.config.forced_decoder_ids = None\n",
    "\n",
    "input_features = whisper_processor(silences, return_tensors=\"pt\", sampling_rate=16000).input_features\n",
    "logits = whisper_for_gen.generate(input_features, max_length=448)\n",
    "\n",
    "decoded = whisper_processor.batch_decode(logits)\n",
    "\n",
    "print(\"silence decoded : {}\".format(decoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset librispeech_asr/clean to C:/Users/shast/.cache/huggingface/datasets/librispeech_asr/clean/2.1.0/cff5df6e7955c80a67f80e27e7e655de71c689e2d2364bece785b972acb37fe7...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ab9c5d43724eeaaa4e47be6f2b0936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c23e426dc4a47a4b1276cb07ef20614",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/338M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "libri_dataset = load_dataset(\"librispeech_asr\", \"clean\", split=\"validation\")\n",
    "print(libri_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict all the tokens # donot suppress any token\n",
    "whisper_for_gen.config.suppress_tokens = []\n",
    "# donot force the decoder to predict the language token and task token initally\n",
    "whisper_for_gen.config.forced_decoder_ids = None\n",
    "\n",
    "input_features = whisper_processor(libri_dataset[0][\"audio\"][\"array\"], return_tensors=\"pt\", sampling_rate=16000).input_features\n",
    "logits = whisper_for_gen.generate(input_features, max_length=448)\n",
    "\n",
    "decoded = whisper_processor.batch_decode(logits)\n",
    "\n",
    "print(\"a datapoint from [librispeech-val-clean] decoded : {}\".format(decoded))\n",
    "print(\"a datapoint from [librispeech-val-clean] original: {}\".format(libri_dataset[0][\"text\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbeb86e5169ae12036faefecf25111d7a89a44034aadf5555bd66a4cc67a8a73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
