{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperModel, WhisperConfig, WhisperFeatureExtractor, WhisperForConditionalGeneration\n",
    "from transformers import WhisperProcessor, WhisperTokenizer\n",
    "from datasets import load_dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"openai/whisper-medium\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_whisper = WhisperModel.from_pretrained(MODEL_NAME)\n",
    "pretrained_whisper_tokenizer = WhisperTokenizer.from_pretrained(MODEL_NAME)\n",
    "whisper_for_gen = WhisperForConditionalGeneration.from_pretrained(MODEL_NAME)\n",
    "whisper_processor = WhisperProcessor.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WhisperConfig {\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"begin_suppress_tokens\": [\n",
      "    220,\n",
      "    50256\n",
      "  ],\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"d_model\": 256,\n",
      "  \"decoder_attention_heads\": 4,\n",
      "  \"decoder_ffn_dim\": 1536,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 50257,\n",
      "  \"dropout\": 0.0,\n",
      "  \"encoder_attention_heads\": 4,\n",
      "  \"encoder_ffn_dim\": 1536,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"max_source_positions\": 1500,\n",
      "  \"max_target_positions\": 448,\n",
      "  \"model_type\": \"whisper\",\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"num_mel_bins\": 80,\n",
      "  \"pad_token_id\": 50256,\n",
      "  \"scale_embedding\": false,\n",
      "  \"transformers_version\": \"4.23.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 51865\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# a look at whisper config\n",
    "config = WhisperConfig()\n",
    "print(config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', '', '<|endoftext|>', '<|startoftranscript|>', '<|en|>', '<|zh|>', '<|de|>', '<|es|>', '<|ru|>', '<|ko|>', '<|fr|>', '<|ja|>', '<|pt|>', '<|tr|>', '<|pl|>', '<|ca|>', '<|nl|>', '<|ar|>', '<|sv|>', '<|it|>', '<|id|>', '<|hi|>', '<|fi|>', '<|vi|>', '<|iw|>', '<|uk|>', '<|el|>', '<|ms|>', '<|cs|>', '<|ro|>', '<|da|>', '<|hu|>', '<|ta|>', '<|no|>', '<|th|>', '<|ur|>', '<|hr|>', '<|bg|>', '<|lt|>', '<|la|>', '<|mi|>', '<|ml|>', '<|cy|>', '<|sk|>', '<|te|>', '<|fa|>', '<|lv|>', '<|bn|>', '<|sr|>', '<|az|>', '<|sl|>', '<|kn|>', '<|et|>', '<|mk|>', '<|br|>', '<|eu|>', '<|is|>', '<|hy|>', '<|ne|>', '<|mn|>', '<|bs|>', '<|kk|>', '<|sq|>', '<|sw|>', '<|gl|>', '<|mr|>', '<|pa|>', '<|si|>', '<|km|>', '<|sn|>', '<|yo|>', '<|so|>', '<|af|>', '<|oc|>', '<|ka|>', '<|be|>', '<|tg|>', '<|sd|>', '<|gu|>', '<|am|>', '<|yi|>', '<|lo|>', '<|uz|>', '<|fo|>', '<|ht|>', '<|ps|>', '<|tk|>', '<|nn|>', '<|mt|>', '<|sa|>', '<|lb|>', '<|my|>', '<|bo|>', '<|tl|>', '<|mg|>', '<|as|>', '<|tt|>', '<|haw|>', '<|ln|>', '<|ha|>', '<|ba|>', '<|jw|>', '<|su|>', '<|translate|>', '<|transcribe|>', '<|startoflm|>', '<|startofprev|>', '<|nocaptions|>', '<|notimestamps|>']\n",
      "BOS token <|endoftext|> ===> 50257\n",
      "EOS token <|endoftext|> ===> 50257\n"
     ]
    }
   ],
   "source": [
    "# look at the special tokens in the whisper_tokenizer\n",
    "# print(pretrained_whisper_tokenizer.all_special_tokens)\n",
    "print(\"BOS token\", pretrained_whisper_tokenizer.bos_token, \"===>\", pretrained_whisper_tokenizer.bos_token_id)\n",
    "print(\"EOS token\", pretrained_whisper_tokenizer.eos_token, \"===>\", pretrained_whisper_tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDs the model is forced to predict at each timestep\n",
      "timestep 1: <|en|> => 50259\n",
      "IDs the model is forced to predict at each timestep\n",
      "timestep 2: <|transcribe|> => 50359\n",
      "IDs the model is forced to predict at each timestep\n",
      "timestep 3: <|notimestamps|> => 50363\n",
      "(\", 1) (#, 2) (', 6) ((, 7) (), 8) (*, 9) (+, 10) (-, 12) (/, 14) (:, 25) (;, 26) (<, 27) (=, 28) (>, 29) (@, 31) ([, 58) (\\, 59) (], 60) (^, 61) (_, 62) (`, 63) ({, 90) (|, 91) (}, 92) (~, 93) ( -, 359) ( \", 503) ( (, 522) ( [, 542) ( �, 873) (>>, 893) ( >>, 902) (--, 918) ( ', 922) ( ♪, 931) ( --, 1350) ( *, 1853) ( :, 1982) ( /, 2460) ( <, 2627) (「, 3246) (」, 3253) (�, 3268) ( #, 3536) ( ♫, 3846) (♪, 3961) ( ], 4183) ( +, 4667) ( =, 6585) ( -(, 6647) ( ), 7273) ( ♪♪, 9061) ()), 9383) ( @, 10428) ( {, 10929) ( ~, 11938) ( \\, 12033) ( >, 12331) ( ;, 12562) ( >>>, 13793) (♫, 14157) ( -[, 14635) ( ((, 15265) ( (\", 15618) (『, 16553) (』, 16604) ( |, 18362) ( ^, 18956) (---, 20075) ( 「, 21675) ( ♬, 22520) (♪♪, 26130) ( _, 26161) ( ))), 26435) ( `, 28279) (}}, 29464) ( ♪♪♪, 31650) ( )), 32302) ( ---, 32470) ( ♩, 36865) (♬, 42863) ( <<, 47425) ( }, 49870) ( (', 50254) (<|startoftranscript|>, 50258) (<|startoflm|>, 50360) (<|startofprev|>, 50361) (<|nocaptions|>, 50362) "
     ]
    }
   ],
   "source": [
    "forced_ids = whisper_for_gen.config.forced_decoder_ids\n",
    "for idx, token_id in forced_ids:\n",
    "    token = pretrained_whisper_tokenizer.decode(token_id)\n",
    "    print(\"IDs the model is forced to predict at each timestep\")\n",
    "    print(f\"timestep {idx}: {token} => {token_id}\")\n",
    "\n",
    "ids_to_suppress = whisper_for_gen.config.suppress_tokens\n",
    "for sup_id in ids_to_suppress:\n",
    "    sup_token = pretrained_whisper_tokenizer.decode(sup_id)\n",
    "    print(f\"({sup_token}, {sup_id})\", end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pretrained_whisper.config.bos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "It is strongly recommended to pass the `sampling_rate` argument to this function. Failing to do so can result in silent errors that might be hard to debug.\n",
      "d:\\Users\\shast\\envs\\whisper_env\\lib\\site-packages\\transformers\\generation_utils.py:1296: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 448 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "silence decoded : ['<|startoftranscript|><|en|><|transcribe|><|notimestamps|> you<|endoftext|>']\n"
     ]
    }
   ],
   "source": [
    "silences = torch.zeros(size=(16000,))\n",
    "whisper_for_gen.config.suppress_tokens = []\n",
    "input_features = whisper_processor(silences, return_tensors=\"pt\").input_features\n",
    "logits = whisper_for_gen.generate(input_features)\n",
    "\n",
    "decoded = whisper_processor.batch_decode(logits)\n",
    "\n",
    "print(\"silence decoded : {}\".format(decoded))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dbeb86e5169ae12036faefecf25111d7a89a44034aadf5555bd66a4cc67a8a73"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
